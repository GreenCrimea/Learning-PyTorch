{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing and loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "machine learning involves:\n",
    "\n",
    "1. get data into a numerical representation\n",
    "2. build a model to learn patterns in that numerical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create *known* parameters\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "\n",
    "Y = weight * X + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train/test split\n",
    "\n",
    "\n",
    "train_split = int(0.8 * len(X))\n",
    "\n",
    "X_train, Y_train = X[:train_split], Y[:train_split]\n",
    "X_test, Y_test = X[train_split:], Y[train_split:]\n",
    "\n",
    "len(X_train), len(Y_train), len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "\n",
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=Y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=Y_test,\n",
    "                     predictions=None):\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    #plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"training data\")\n",
    "\n",
    "    #plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"test data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "\n",
    "        #plot predictions in red if they exist\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"predictions\")\n",
    "\n",
    "    #show the legend\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linear regression model class\n",
    "\n",
    "class LinearRegressionModel(nn.Module):     # almost all pytorch classes inherit from nn.module\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, \n",
    "                                                requires_grad=True,\n",
    "                                                dtype=torch.float32))\n",
    "                                                \n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float32))\n",
    "\n",
    "    #forward method to define the computation in the model\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * X + self.bias\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random seed\n",
    "torch.manual_seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate model\n",
    "\n",
    "model_0 = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what the model contains\n",
    "print(list(model_0.parameters()))\n",
    "print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions with model\n",
    "with torch.inference_mode():\n",
    "    Y_pred = model_0(X_test)\n",
    "\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup loss func\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#setup optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), \n",
    "                            lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model_0.train()\n",
    "\n",
    "    Y_pred = model_0(X_train)\n",
    "    \n",
    "    loss = loss_fn(Y_pred, Y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_0(X_test)\n",
    "\n",
    "        test_loss = loss_fn(test_pred, Y_test)\n",
    "        print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "\n",
    "\n",
    "model_path = Path(\"models\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_name = \"model_0.pth\"\n",
    "save_path = model_path / model_name\n",
    "\n",
    "torch.save(obj=model_0.state_dict(), f=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "model_0_1 = LinearRegressionModel()\n",
    "\n",
    "model_0_1.load_state_dict(torch.load(f=save_path))\n",
    "\n",
    "model_0.state_dict(), model_0_1.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7d1e8cf4ad6457268417d8c2bdfad5150dd68a8f64a3fdc24460c3366abf524"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
