{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import make_circles\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 1000 samples\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create circles\n",
    "from torch import rand\n",
    "\n",
    "\n",
    "x, y = make_circles(n_samples,\n",
    "                    noise=0.03,\n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataframe of circle data\n",
    "circles = pd.DataFrame({\"x1\": x[:, 0],\n",
    "                        \"x2\": x[:, 1],\n",
    "                        \"label\": y})\n",
    "circles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise\n",
    "plt.scatter(x=x[:, 0],\n",
    "            y=x[:, 1],\n",
    "            c=y,\n",
    "            cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view first sample\n",
    "x_sample = x[0]\n",
    "y_sample = y[0]\n",
    "\n",
    "print(f\"{x_sample}, {y_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## turn data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn data into tensors\n",
    "X = torch.from_numpy(x).type(torch.float)\n",
    "Y = torch.from_numpy(y).type(torch.float)\n",
    "\n",
    "X[:5], Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train / test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleModelV0(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=5)     # input layer\n",
    "        self.layer_2 = nn.Linear(in_features=5, out_features=1)     # hidden layer\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_2(self.layer_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate\n",
    "model_1 = CircleModelV0()\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same model with nn.Sequential()\n",
    "model_2 = nn.Sequential(\n",
    "    nn.Linear(in_features=2, out_features=5),\n",
    "    nn.Linear(in_features=5, out_features=1)\n",
    ")\n",
    "\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "with torch.inference_mode():\n",
    "    untrained_pred = model_2(X_test)\n",
    "    print(f\"len = {len(untrained_pred.round().abs())}, shape = {untrained_pred.shape}\")\n",
    "    print(f\"len = {len(X_test)}, shape = {X_test.shape}\")\n",
    "    print(untrained_pred[:10].round().abs())\n",
    "    print(Y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for classification, best loss funcs are adam, BCE and SGD for optim\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create optimizer\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
    "                           lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy (what % is correct)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 5 outputs\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_2(X_test[:5])\n",
    "y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use sigmoid activation function\n",
    "y_pred_probs = torch.sigmoid(y_logits)\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find predicted labels\n",
    "y_preds = torch.round(y_pred_probs)\n",
    "\n",
    "y_pred_labels = torch.round(torch.sigmoid(model_2(X_test[:5])))\n",
    "\n",
    "print(torch.eq(y_preds.squeeze(), y_pred_labels.squeeze()))\n",
    "\n",
    "y_preds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build train and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model_2.train()\n",
    "\n",
    "    y_logits = model_2(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    loss = loss_fn(y_logits,\n",
    "                   Y_train)\n",
    "\n",
    "    acc = accuracy_fn(y_true=Y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_2.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_2(X_test).squeeze()\n",
    "\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        test_loss = loss_fn(test_logits, Y_test)\n",
    "\n",
    "        test_acc = accuracy_fn(y_true=Y_test, y_pred=test_pred)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"epoch: {epoch} | loss: {loss:.5f} | acc: {acc:.2f}% | test_loss: {test_loss:.5f} | test_acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model: torch.nn.Module, X: torch.Tensor, y: torch.Tensor):\n",
    "    \"\"\"Plots decision boundaries of model predicting on X in comparison to y.\n",
    "    Source - https://madewithml.com/courses/foundations/neural-networks/ (with modifications)\n",
    "    \"\"\"\n",
    "    # Put everything to CPU (works better with NumPy + Matplotlib)\n",
    "    model.to(\"cpu\")\n",
    "    X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
    "\n",
    "    # Setup prediction boundaries and grid\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
    "\n",
    "    # Make features\n",
    "    X_to_pred_on = torch.from_numpy(np.column_stack((xx.ravel(), yy.ravel()))).float()\n",
    "\n",
    "    # Make predictions\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_logits = model(X_to_pred_on)\n",
    "\n",
    "    # Test for multi-class or binary and adjust logits to prediction labels\n",
    "    if len(torch.unique(y)) > 2:\n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)  # mutli-class\n",
    "    else:\n",
    "        y_pred = torch.round(torch.sigmoid(y_logits))  # binary\n",
    "\n",
    "    # Reshape preds and plot\n",
    "    y_pred = y_pred.reshape(xx.shape).detach().numpy()\n",
    "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot decision boundary of model\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"train\")\n",
    "plot_decision_boundary(model_3, X_train, Y_train)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"test\")\n",
    "plot_decision_boundary(model_3, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improve model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "possibilities\n",
    "\n",
    "* add more layers\n",
    "* add more hidden units\n",
    "* learn for longer\n",
    "* change the activation function\n",
    "* change the learning rate\n",
    "* change the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleModelV1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.layer_2(self.layer_1(x)))\n",
    "\n",
    "model_3 = CircleModelV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loss func\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#create optimizer\n",
    "optimizer = torch.optim.SGD(params=model_3.parameters(),\n",
    "                           lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model_3.train()\n",
    "\n",
    "    y_logits = model_3(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    loss = loss_fn(y_logits,\n",
    "                   Y_train)\n",
    "\n",
    "    acc = accuracy_fn(y_true=Y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_3.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_3(X_test).squeeze()\n",
    "\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        test_loss = loss_fn(test_logits, Y_test)\n",
    "\n",
    "        test_acc = accuracy_fn(y_true=Y_test, y_pred=test_pred)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch} | loss: {loss:.5f} | acc: {acc:.2f}% | test_loss: {test_loss:.5f} | test_acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test if model can learn linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.01\n",
    "\n",
    "X_regression = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "\n",
    "y_regression = weight * X_regression + bias\n",
    "\n",
    "#check data\n",
    "print(len(X_regression))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split\n",
    "\n",
    "train_split = int(0.8 * len(X_regression))\n",
    "X_train_r, y_train_r = X_regression[:train_split], y_regression[:train_split]\n",
    "X_test_r, y_test_r = X_regression[train_split:], y_regression[train_split:]\n",
    "\n",
    "len(X_train_r), len(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear data or training and test and predictions (optional)\n",
    "def plot_predictions(\n",
    "    train_data, train_labels, test_data, test_labels, predictions=None\n",
    "):\n",
    "    \"\"\"\n",
    "  Plots linear training data and test data and compares predictions.\n",
    "  \"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions in red (predictions were made on the test data)\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(train_data=X_train_r,\n",
    "                 train_labels=y_train_r,\n",
    "                 test_data=X_test_r,\n",
    "                 test_labels=y_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleModelV1_1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=1, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.layer_2(self.layer_1(x)))\n",
    "\n",
    "model_3_1 = CircleModelV1_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loss func\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#create optimizer\n",
    "optimizer = torch.optim.SGD(params=model_3_1.parameters(),\n",
    "                           lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    y_pred = model_3_1(X_train_r)\n",
    "\n",
    "    loss = loss_fn(y_pred,\n",
    "                   y_train_r)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_3_1.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "\n",
    "        test_pred = model_3_1(X_test_r)\n",
    "\n",
    "        test_loss = loss_fn(test_pred, y_test_r)\n",
    "\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch} | loss: {loss:.5f} | test_loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_1.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_3_1(X_test_r)\n",
    "\n",
    "plot_predictions(train_data=X_train_r,\n",
    "                 train_labels=y_train_r,\n",
    "                 test_data=X_test_r,\n",
    "                 test_labels=y_test_r,\n",
    "                 predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non-linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleModelV2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(in_features=2, out_features=10)\n",
    "        self.layer_2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "model_4 = CircleModelV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create optimizer\n",
    "optimizer = torch.optim.SGD(params=model_4.parameters(),\n",
    "                           lr=0.5)\n",
    "\n",
    "#create loss func\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    model_4.train()\n",
    "\n",
    "    y_logits = model_4(X_train).squeeze()\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "    loss = loss_fn(y_logits,\n",
    "                   Y_train)\n",
    "\n",
    "    acc = accuracy_fn(y_true=Y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_4.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_4(X_test).squeeze()\n",
    "\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "        test_loss = loss_fn(test_logits, Y_test)\n",
    "\n",
    "        test_acc = accuracy_fn(y_true=Y_test, y_pred=test_pred)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch} | loss: {loss:.5f} | acc: {acc:.2f}% | test_loss: {test_loss:.5f} | test_acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot decision boundary of model\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"train\")\n",
    "plot_decision_boundary(model_4, X_train, Y_train)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"test\")\n",
    "plot_decision_boundary(model_4, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replicate non-linear activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.arange(-10., 10., 1.)\n",
    "A.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.relu(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.maximum(torch.tensor(0), x)\n",
    "\n",
    "plt.plot(relu(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.sigmoid(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "plt.plot(sigmoid(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "NUM_FEATURES = 2\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data\n",
    "x_blob, y_blob = make_blobs(n_samples=1000,\n",
    "                            n_features=NUM_FEATURES,\n",
    "                            centers=NUM_CLASSES,\n",
    "                            cluster_std=1.5,\n",
    "                            random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn data into tensors\n",
    "x_blob = torch.from_numpy(x_blob).type(torch.float)\n",
    "y_blob = torch.from_numpy(y_blob).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "x_blob_t, x_blob_test, y_blob_t, y_blob_test = train_test_split(x_blob, y_blob, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(x_blob[:, 0], x_blob[:, 1], c=y_blob, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "\n",
    "\n",
    "class BlobModelV0(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "model_5 = BlobModelV0(input_features=2, output_features=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_5.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see current outputs\n",
    "model_5.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_5(x_blob_test)\n",
    "    y_pred_probs = torch.softmax(y_logits, dim=1)\n",
    "    y_preds = torch.argmax(y_pred_probs, dim=1)\n",
    "    print(y_preds[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_5.train()\n",
    "\n",
    "    y_logits = model_5(x_blob_t)\n",
    "    y_preds = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "    loss = loss_fn(y_logits, y_blob_t)\n",
    "\n",
    "    acc = accuracy_fn(y_true=y_blob_t, y_pred=y_preds)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_5.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_5(x_blob_test)\n",
    "        test_preds = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "\n",
    "        test_acc = accuracy_fn(y_true=y_blob_test, y_pred=test_preds)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch = {epoch}\")\n",
    "            print(f\"loss = {loss:4f} | acc = {acc:2f} | test loss = {test_loss:4f} | test acc = {test_acc:2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "\n",
    "model_5.eval()\n",
    "with torch.inference_mode():\n",
    "    y_logits = model_5(x_blob_test)\n",
    "    y_preds = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"train\")\n",
    "plot_decision_boundary(model_5, x_blob_t, y_blob_t)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"test\")\n",
    "plot_decision_boundary(model_5, x_blob_test, y_blob_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another more advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "\n",
    "NUM_CLASSES = 20\n",
    "NUM_FEATURES = 3\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data\n",
    "x_blob, y_blob = make_blobs(n_samples=1000,\n",
    "                            n_features=NUM_FEATURES,\n",
    "                            centers=NUM_CLASSES,\n",
    "                            cluster_std=1,\n",
    "                            random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn data into tensors\n",
    "x_blob = torch.from_numpy(x_blob).type(torch.float)\n",
    "y_blob = torch.from_numpy(y_blob).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "x_blob_t, x_blob_test, y_blob_t, y_blob_test = train_test_split(x_blob, y_blob, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plot = fig.add_subplot(projection=\"3d\")\n",
    "plot.scatter(x_blob[:, 0], x_blob[:, 1], x_blob[:, 2], c=y_blob, cmap=plt.cm.RdYlBu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "\n",
    "\n",
    "class BlobModelV1(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "model_6 = BlobModelV0(input_features=3, output_features=20, hidden_units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_6.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_5.train()\n",
    "\n",
    "    y_logits = model_6(x_blob_t)\n",
    "    y_preds = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "    loss = loss_fn(y_logits, y_blob_t)\n",
    "\n",
    "    acc = accuracy_fn(y_true=y_blob_t, y_pred=y_preds)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_6.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_6(x_blob_test)\n",
    "        test_preds = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "\n",
    "        test_acc = accuracy_fn(y_true=y_blob_test, y_pred=test_preds)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch = {epoch}\")\n",
    "            print(f\"loss = {loss:4f} | acc = {acc:2f} | test loss = {test_loss:4f} | test acc = {test_acc:2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "\n",
    "\n",
    "class BlobModelV2(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features, output_features, hidden_units=8):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "model_7 = BlobModelV0(input_features=3, output_features=20, hidden_units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_7.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_7.train()\n",
    "\n",
    "    y_logits = model_7(x_blob_t)\n",
    "    y_preds = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "    loss = loss_fn(y_logits, y_blob_t)\n",
    "\n",
    "    acc = accuracy_fn(y_true=y_blob_t, y_pred=y_preds)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model_6.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_logits = model_7(x_blob_test)\n",
    "        test_preds = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "        test_loss = loss_fn(test_logits, y_blob_test)\n",
    "\n",
    "        test_acc = accuracy_fn(y_true=y_blob_test, y_pred=test_preds)\n",
    "\n",
    "        if epoch % 250 == 0:\n",
    "            print(f\"epoch = {epoch}\")\n",
    "            print(f\"loss = {loss:4f} | acc = {acc:2f} | test loss = {test_loss:4f} | test acc = {test_acc:2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7d1e8cf4ad6457268417d8c2bdfad5150dd68a8f64a3fdc24460c3366abf524"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
